2023-02-04 23:56:00,122 INFO    StreamThr :10952 [internal.py:wandb_internal():87] W&B internal server running at pid: 10952, started at: 2023-02-04 23:56:00.122262
2023-02-04 23:56:00,123 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: status
2023-02-04 23:56:00,125 INFO    WriterThread:10952 [datastore.py:open_for_write():85] open: /home/lume/KARPATHY/nanoGPT/wandb/run-20230204_235600-ge9paqob/run-ge9paqob.wandb
2023-02-04 23:56:00,125 DEBUG   SenderThread:10952 [sender.py:send():334] send: header
2023-02-04 23:56:00,158 DEBUG   SenderThread:10952 [sender.py:send():334] send: run
2023-02-04 23:56:00,577 INFO    SenderThread:10952 [dir_watcher.py:__init__():216] watching files in: /home/lume/KARPATHY/nanoGPT/wandb/run-20230204_235600-ge9paqob/files
2023-02-04 23:56:00,577 INFO    SenderThread:10952 [sender.py:_start_run_threads():1065] run started: ge9paqob with start time 1675565760.121655
2023-02-04 23:56:00,577 DEBUG   SenderThread:10952 [sender.py:send_request():361] send_request: summary_record
2023-02-04 23:56:00,577 INFO    SenderThread:10952 [sender.py:_save_file():1319] saving file wandb-summary.json with policy end
2023-02-04 23:56:00,580 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: check_version
2023-02-04 23:56:00,581 DEBUG   SenderThread:10952 [sender.py:send_request():361] send_request: check_version
2023-02-04 23:56:00,665 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: run_start
2023-02-04 23:56:00,670 DEBUG   HandlerThread:10952 [system_info.py:__init__():31] System info init
2023-02-04 23:56:00,670 DEBUG   HandlerThread:10952 [system_info.py:__init__():46] System info init done
2023-02-04 23:56:00,670 INFO    HandlerThread:10952 [system_monitor.py:start():151] Starting system monitor
2023-02-04 23:56:00,670 INFO    SystemMonitor:10952 [system_monitor.py:_start():116] Starting system asset monitoring threads
2023-02-04 23:56:00,670 INFO    HandlerThread:10952 [system_monitor.py:probe():172] Collecting system info
2023-02-04 23:56:00,670 INFO    SystemMonitor:10952 [interfaces.py:start():168] Started cpu
2023-02-04 23:56:00,671 INFO    SystemMonitor:10952 [interfaces.py:start():168] Started disk
2023-02-04 23:56:00,671 INFO    SystemMonitor:10952 [interfaces.py:start():168] Started gpu
2023-02-04 23:56:00,672 INFO    SystemMonitor:10952 [interfaces.py:start():168] Started memory
2023-02-04 23:56:00,672 INFO    SystemMonitor:10952 [interfaces.py:start():168] Started network
2023-02-04 23:56:00,678 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:56:00,693 DEBUG   HandlerThread:10952 [system_info.py:probe():195] Probing system
2023-02-04 23:56:00,697 DEBUG   HandlerThread:10952 [system_info.py:_probe_git():180] Probing git
2023-02-04 23:56:00,706 DEBUG   HandlerThread:10952 [system_info.py:_probe_git():188] Probing git done
2023-02-04 23:56:00,706 DEBUG   HandlerThread:10952 [system_info.py:probe():241] Probing system done
2023-02-04 23:56:00,706 DEBUG   HandlerThread:10952 [system_monitor.py:probe():181] {'os': 'Linux-5.15.0-46-generic-x86_64-with-glibc2.29', 'python': '3.8.10', 'heartbeatAt': '2023-02-05T02:56:00.693980', 'startedAt': '2023-02-05T02:56:00.118335', 'docker': None, 'cuda': None, 'args': ('config/train_alberto_gpt2.py', '--compile=False'), 'state': 'running', 'program': 'train.py', 'codePath': 'train.py', 'git': {'remote': 'https://github.com/karpathy/nanoGPT.git', 'commit': '3fd4c0c5efb653a9e22d88803e13c51832e37a46'}, 'email': 'alberto@lcad.inf.ufes.br', 'root': '/home/lume/KARPATHY/nanoGPT', 'host': 'lume-h4', 'username': 'lume', 'executable': '/usr/bin/python3', 'cpu_count': 8, 'cpu_count_logical': 16, 'cpu_freq': {'current': 2419.9375, 'min': 800.0, 'max': 4600.0}, 'cpu_freq_per_core': [{'current': 2300.0, 'min': 800.0, 'max': 4600.0}, {'current': 2300.0, 'min': 800.0, 'max': 4600.0}, {'current': 2300.0, 'min': 800.0, 'max': 4600.0}, {'current': 2300.0, 'min': 800.0, 'max': 4600.0}, {'current': 2300.0, 'min': 800.0, 'max': 4600.0}, {'current': 2300.0, 'min': 800.0, 'max': 4600.0}, {'current': 2300.0, 'min': 800.0, 'max': 4600.0}, {'current': 4219.0, 'min': 800.0, 'max': 4600.0}, {'current': 2300.0, 'min': 800.0, 'max': 4600.0}, {'current': 2300.0, 'min': 800.0, 'max': 4600.0}, {'current': 2300.0, 'min': 800.0, 'max': 4600.0}, {'current': 2300.0, 'min': 800.0, 'max': 4600.0}, {'current': 2300.0, 'min': 800.0, 'max': 4600.0}, {'current': 2300.0, 'min': 800.0, 'max': 4600.0}, {'current': 3769.033, 'min': 800.0, 'max': 4600.0}, {'current': 2300.0, 'min': 800.0, 'max': 4600.0}], 'disk': {'total': 1344.4707374572754, 'used': 736.5210647583008}, 'gpu': 'NVIDIA GeForce RTX 3060 Laptop GPU', 'gpu_count': 1, 'gpu_devices': [{'name': 'NVIDIA GeForce RTX 3060 Laptop GPU', 'memory_total': 6442450944}], 'memory': {'total': 15.407585144042969}}
2023-02-04 23:56:00,706 INFO    HandlerThread:10952 [system_monitor.py:probe():182] Finished collecting system info
2023-02-04 23:56:00,706 INFO    HandlerThread:10952 [system_monitor.py:probe():185] Publishing system info
2023-02-04 23:56:00,706 DEBUG   HandlerThread:10952 [system_info.py:_save_pip():51] Saving list of pip packages installed into the current environment
2023-02-04 23:56:00,706 DEBUG   HandlerThread:10952 [system_info.py:_save_pip():67] Saving pip packages done
2023-02-04 23:56:00,707 INFO    HandlerThread:10952 [system_monitor.py:probe():187] Finished publishing system info
2023-02-04 23:56:00,708 DEBUG   SenderThread:10952 [sender.py:send():334] send: files
2023-02-04 23:56:00,708 INFO    SenderThread:10952 [sender.py:_save_file():1319] saving file wandb-metadata.json with policy now
2023-02-04 23:56:00,711 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: stop_status
2023-02-04 23:56:00,711 DEBUG   SenderThread:10952 [sender.py:send_request():361] send_request: stop_status
2023-02-04 23:56:00,896 DEBUG   SenderThread:10952 [sender.py:send():334] send: telemetry
2023-02-04 23:56:01,350 INFO    Thread-16 :10952 [upload_job.py:push():143] Uploaded file /tmp/tmp096y01ozwandb/f9lm4lqd-wandb-metadata.json
2023-02-04 23:56:01,578 INFO    Thread-13 :10952 [dir_watcher.py:_on_file_created():275] file/dir created: /home/lume/KARPATHY/nanoGPT/wandb/run-20230204_235600-ge9paqob/files/wandb-metadata.json
2023-02-04 23:56:01,578 INFO    Thread-13 :10952 [dir_watcher.py:_on_file_created():275] file/dir created: /home/lume/KARPATHY/nanoGPT/wandb/run-20230204_235600-ge9paqob/files/wandb-summary.json
2023-02-04 23:56:01,578 INFO    Thread-13 :10952 [dir_watcher.py:_on_file_created():275] file/dir created: /home/lume/KARPATHY/nanoGPT/wandb/run-20230204_235600-ge9paqob/files/requirements.txt
2023-02-04 23:56:02,679 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:56:04,681 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:56:05,897 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: status_report
2023-02-04 23:56:06,682 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:56:08,684 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:56:10,685 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:56:10,898 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: status_report
2023-02-04 23:56:12,687 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:56:14,689 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:56:15,737 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: keepalive
2023-02-04 23:56:15,737 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: keepalive
2023-02-04 23:56:15,898 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: status_report
2023-02-04 23:56:16,690 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:56:18,692 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:56:18,817 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: partial_history
2023-02-04 23:56:18,818 DEBUG   SenderThread:10952 [sender.py:send():334] send: history
2023-02-04 23:56:18,819 DEBUG   SenderThread:10952 [sender.py:send_request():361] send_request: summary_record
2023-02-04 23:56:18,820 INFO    SenderThread:10952 [sender.py:_save_file():1319] saving file wandb-summary.json with policy end
2023-02-04 23:56:19,582 INFO    Thread-13 :10952 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/lume/KARPATHY/nanoGPT/wandb/run-20230204_235600-ge9paqob/files/wandb-summary.json
2023-02-04 23:56:19,582 INFO    Thread-13 :10952 [dir_watcher.py:_on_file_created():275] file/dir created: /home/lume/KARPATHY/nanoGPT/wandb/run-20230204_235600-ge9paqob/files/output.log
2023-02-04 23:56:20,694 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:56:20,773 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: keepalive
2023-02-04 23:56:21,453 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: status_report
2023-02-04 23:56:21,582 INFO    Thread-13 :10952 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/lume/KARPATHY/nanoGPT/wandb/run-20230204_235600-ge9paqob/files/output.log
2023-02-04 23:56:22,696 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:56:24,698 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:56:25,773 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: keepalive
2023-02-04 23:56:26,700 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:56:26,746 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: status_report
2023-02-04 23:56:27,584 INFO    Thread-13 :10952 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/lume/KARPATHY/nanoGPT/wandb/run-20230204_235600-ge9paqob/files/output.log
2023-02-04 23:56:28,702 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:56:30,723 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:56:30,774 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: keepalive
2023-02-04 23:56:31,749 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: status_report
2023-02-04 23:56:32,585 INFO    Thread-13 :10952 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/lume/KARPATHY/nanoGPT/wandb/run-20230204_235600-ge9paqob/files/config.yaml
2023-02-04 23:56:32,724 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:56:33,585 INFO    Thread-13 :10952 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/lume/KARPATHY/nanoGPT/wandb/run-20230204_235600-ge9paqob/files/output.log
2023-02-04 23:56:34,727 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:56:35,775 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: keepalive
2023-02-04 23:56:36,729 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:56:37,037 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: status_report
2023-02-04 23:56:38,731 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:56:39,587 INFO    Thread-13 :10952 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/lume/KARPATHY/nanoGPT/wandb/run-20230204_235600-ge9paqob/files/output.log
2023-02-04 23:56:40,734 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:56:40,776 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: keepalive
2023-02-04 23:56:42,330 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: status_report
2023-02-04 23:56:42,736 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:56:44,739 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:56:45,776 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: keepalive
2023-02-04 23:56:46,740 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:56:47,589 INFO    Thread-13 :10952 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/lume/KARPATHY/nanoGPT/wandb/run-20230204_235600-ge9paqob/files/output.log
2023-02-04 23:56:47,628 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: status_report
2023-02-04 23:56:48,743 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:56:50,745 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:56:50,777 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: keepalive
2023-02-04 23:56:52,748 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:56:52,932 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: status_report
2023-02-04 23:56:53,590 INFO    Thread-13 :10952 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/lume/KARPATHY/nanoGPT/wandb/run-20230204_235600-ge9paqob/files/output.log
2023-02-04 23:56:54,750 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:56:55,778 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: keepalive
2023-02-04 23:56:56,752 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:56:58,241 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: status_report
2023-02-04 23:56:58,755 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:56:59,592 INFO    Thread-13 :10952 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/lume/KARPATHY/nanoGPT/wandb/run-20230204_235600-ge9paqob/files/output.log
2023-02-04 23:57:00,672 DEBUG   SystemMonitor:10952 [system_monitor.py:_start():130] Starting system metrics aggregation loop
2023-02-04 23:57:00,673 DEBUG   SenderThread:10952 [sender.py:send():334] send: stats
2023-02-04 23:57:00,778 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: keepalive
2023-02-04 23:57:00,778 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:57:02,781 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:57:03,550 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: status_report
2023-02-04 23:57:04,785 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:57:05,593 INFO    Thread-13 :10952 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/lume/KARPATHY/nanoGPT/wandb/run-20230204_235600-ge9paqob/files/output.log
2023-02-04 23:57:05,779 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: keepalive
2023-02-04 23:57:06,788 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:57:08,551 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: status_report
2023-02-04 23:57:08,791 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:57:10,780 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: keepalive
2023-02-04 23:57:10,794 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:57:11,594 INFO    Thread-13 :10952 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/lume/KARPATHY/nanoGPT/wandb/run-20230204_235600-ge9paqob/files/output.log
2023-02-04 23:57:12,796 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:57:13,866 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: status_report
2023-02-04 23:57:14,799 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:57:15,780 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: keepalive
2023-02-04 23:57:16,805 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:57:17,596 INFO    Thread-13 :10952 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/lume/KARPATHY/nanoGPT/wandb/run-20230204_235600-ge9paqob/files/output.log
2023-02-04 23:57:18,807 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:57:19,180 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: status_report
2023-02-04 23:57:20,781 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: keepalive
2023-02-04 23:57:20,810 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:57:22,813 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:57:24,494 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: status_report
2023-02-04 23:57:24,816 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:57:25,598 INFO    Thread-13 :10952 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/lume/KARPATHY/nanoGPT/wandb/run-20230204_235600-ge9paqob/files/output.log
2023-02-04 23:57:25,781 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: keepalive
2023-02-04 23:57:26,819 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:57:28,822 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:57:29,809 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: status_report
2023-02-04 23:57:30,673 DEBUG   SenderThread:10952 [sender.py:send():334] send: stats
2023-02-04 23:57:30,808 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: keepalive
2023-02-04 23:57:30,845 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:57:31,599 INFO    Thread-13 :10952 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/lume/KARPATHY/nanoGPT/wandb/run-20230204_235600-ge9paqob/files/output.log
2023-02-04 23:57:32,847 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:57:34,851 ERROR   gpu       :10952 [interfaces.py:monitor():129] Failed to sample metric: Not Supported
2023-02-04 23:57:35,124 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: status_report
2023-02-04 23:57:35,808 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: keepalive
2023-02-04 23:57:35,827 DEBUG   SenderThread:10952 [sender.py:send():334] send: exit
2023-02-04 23:57:35,828 INFO    SenderThread:10952 [sender.py:send_exit():557] handling exit code: 255
2023-02-04 23:57:35,828 INFO    SenderThread:10952 [sender.py:send_exit():559] handling runtime: 95
2023-02-04 23:57:35,829 INFO    SenderThread:10952 [sender.py:_save_file():1319] saving file wandb-summary.json with policy end
2023-02-04 23:57:35,829 INFO    SenderThread:10952 [sender.py:send_exit():565] send defer
2023-02-04 23:57:35,829 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: defer
2023-02-04 23:57:35,829 INFO    HandlerThread:10952 [handler.py:handle_request_defer():170] handle defer: 0
2023-02-04 23:57:35,829 DEBUG   SenderThread:10952 [sender.py:send_request():361] send_request: defer
2023-02-04 23:57:35,829 INFO    SenderThread:10952 [sender.py:send_request_defer():581] handle sender defer: 0
2023-02-04 23:57:35,829 INFO    SenderThread:10952 [sender.py:transition_state():585] send defer: 1
2023-02-04 23:57:35,829 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: defer
2023-02-04 23:57:35,829 INFO    HandlerThread:10952 [handler.py:handle_request_defer():170] handle defer: 1
2023-02-04 23:57:35,830 DEBUG   SenderThread:10952 [sender.py:send_request():361] send_request: defer
2023-02-04 23:57:35,830 INFO    SenderThread:10952 [sender.py:send_request_defer():581] handle sender defer: 1
2023-02-04 23:57:35,830 INFO    SenderThread:10952 [sender.py:transition_state():585] send defer: 2
2023-02-04 23:57:35,830 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: defer
2023-02-04 23:57:35,830 INFO    HandlerThread:10952 [handler.py:handle_request_defer():170] handle defer: 2
2023-02-04 23:57:35,830 INFO    HandlerThread:10952 [system_monitor.py:finish():161] Stopping system monitor
2023-02-04 23:57:35,830 DEBUG   SystemMonitor:10952 [system_monitor.py:_start():137] Finished system metrics aggregation loop
2023-02-04 23:57:35,830 DEBUG   SystemMonitor:10952 [system_monitor.py:_start():141] Publishing last batch of metrics
2023-02-04 23:57:35,831 INFO    HandlerThread:10952 [interfaces.py:finish():175] Joined cpu
2023-02-04 23:57:35,831 INFO    HandlerThread:10952 [interfaces.py:finish():175] Joined disk
2023-02-04 23:57:35,856 INFO    HandlerThread:10952 [interfaces.py:finish():175] Joined gpu
2023-02-04 23:57:35,856 INFO    HandlerThread:10952 [interfaces.py:finish():175] Joined memory
2023-02-04 23:57:35,856 INFO    HandlerThread:10952 [interfaces.py:finish():175] Joined network
2023-02-04 23:57:35,856 DEBUG   SenderThread:10952 [sender.py:send_request():361] send_request: defer
2023-02-04 23:57:35,856 INFO    SenderThread:10952 [sender.py:send_request_defer():581] handle sender defer: 2
2023-02-04 23:57:35,856 INFO    SenderThread:10952 [sender.py:transition_state():585] send defer: 3
2023-02-04 23:57:35,856 DEBUG   SenderThread:10952 [sender.py:send():334] send: stats
2023-02-04 23:57:35,856 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: defer
2023-02-04 23:57:35,857 INFO    HandlerThread:10952 [handler.py:handle_request_defer():170] handle defer: 3
2023-02-04 23:57:35,857 DEBUG   SenderThread:10952 [sender.py:send_request():361] send_request: defer
2023-02-04 23:57:35,857 INFO    SenderThread:10952 [sender.py:send_request_defer():581] handle sender defer: 3
2023-02-04 23:57:35,857 INFO    SenderThread:10952 [sender.py:transition_state():585] send defer: 4
2023-02-04 23:57:35,857 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: defer
2023-02-04 23:57:35,857 INFO    HandlerThread:10952 [handler.py:handle_request_defer():170] handle defer: 4
2023-02-04 23:57:35,857 DEBUG   SenderThread:10952 [sender.py:send_request():361] send_request: defer
2023-02-04 23:57:35,857 INFO    SenderThread:10952 [sender.py:send_request_defer():581] handle sender defer: 4
2023-02-04 23:57:35,857 INFO    SenderThread:10952 [sender.py:transition_state():585] send defer: 5
2023-02-04 23:57:35,857 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: defer
2023-02-04 23:57:35,857 INFO    HandlerThread:10952 [handler.py:handle_request_defer():170] handle defer: 5
2023-02-04 23:57:35,857 DEBUG   SenderThread:10952 [sender.py:send():334] send: summary
2023-02-04 23:57:35,858 INFO    SenderThread:10952 [sender.py:_save_file():1319] saving file wandb-summary.json with policy end
2023-02-04 23:57:35,858 DEBUG   SenderThread:10952 [sender.py:send_request():361] send_request: defer
2023-02-04 23:57:35,858 INFO    SenderThread:10952 [sender.py:send_request_defer():581] handle sender defer: 5
2023-02-04 23:57:35,858 INFO    SenderThread:10952 [sender.py:transition_state():585] send defer: 6
2023-02-04 23:57:35,858 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: defer
2023-02-04 23:57:35,858 INFO    HandlerThread:10952 [handler.py:handle_request_defer():170] handle defer: 6
2023-02-04 23:57:35,858 DEBUG   SenderThread:10952 [sender.py:send_request():361] send_request: defer
2023-02-04 23:57:35,858 INFO    SenderThread:10952 [sender.py:send_request_defer():581] handle sender defer: 6
2023-02-04 23:57:35,858 INFO    SenderThread:10952 [sender.py:transition_state():585] send defer: 7
2023-02-04 23:57:35,858 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: status_report
2023-02-04 23:57:35,858 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: defer
2023-02-04 23:57:35,858 INFO    HandlerThread:10952 [handler.py:handle_request_defer():170] handle defer: 7
2023-02-04 23:57:35,858 DEBUG   SenderThread:10952 [sender.py:send_request():361] send_request: defer
2023-02-04 23:57:35,858 INFO    SenderThread:10952 [sender.py:send_request_defer():581] handle sender defer: 7
2023-02-04 23:57:36,601 INFO    Thread-13 :10952 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/lume/KARPATHY/nanoGPT/wandb/run-20230204_235600-ge9paqob/files/wandb-summary.json
2023-02-04 23:57:36,828 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: poll_exit
2023-02-04 23:57:37,601 INFO    Thread-13 :10952 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/lume/KARPATHY/nanoGPT/wandb/run-20230204_235600-ge9paqob/files/output.log
2023-02-04 23:57:37,828 INFO    SenderThread:10952 [sender.py:transition_state():585] send defer: 8
2023-02-04 23:57:37,829 DEBUG   SenderThread:10952 [sender.py:send_request():361] send_request: poll_exit
2023-02-04 23:57:37,829 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: defer
2023-02-04 23:57:37,829 INFO    HandlerThread:10952 [handler.py:handle_request_defer():170] handle defer: 8
2023-02-04 23:57:37,829 DEBUG   SenderThread:10952 [sender.py:send_request():361] send_request: defer
2023-02-04 23:57:37,829 INFO    SenderThread:10952 [sender.py:send_request_defer():581] handle sender defer: 8
2023-02-04 23:57:37,832 INFO    SenderThread:10952 [sender.py:transition_state():585] send defer: 9
2023-02-04 23:57:37,833 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: defer
2023-02-04 23:57:37,833 INFO    HandlerThread:10952 [handler.py:handle_request_defer():170] handle defer: 9
2023-02-04 23:57:37,833 DEBUG   SenderThread:10952 [sender.py:send():334] send: artifact
2023-02-04 23:57:38,601 INFO    Thread-13 :10952 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/lume/KARPATHY/nanoGPT/wandb/run-20230204_235600-ge9paqob/files/output.log
2023-02-04 23:57:38,923 INFO    SenderThread:10952 [sender.py:send_artifact():1415] sent artifact job-https___github.com_karpathy_nanoGPT.git_train.py - {'id': 'QXJ0aWZhY3Q6MzU0OTIyNTUw', 'digest': '386b66cf2971e4b2c806b423b46c797a', 'state': 'COMMITTED', 'aliases': [{'artifactCollectionName': 'job-https___github.com_karpathy_nanoGPT.git_train.py', 'alias': 'v7'}], 'artifactSequence': {'id': 'QXJ0aWZhY3RDb2xsZWN0aW9uOjUxMjk1MDc2', 'latestArtifact': {'id': 'QXJ0aWZhY3Q6MzU0OTIyNTUw', 'versionIndex': 7}}, 'version': 'v7'}
2023-02-04 23:57:38,923 DEBUG   SenderThread:10952 [sender.py:send_request():361] send_request: defer
2023-02-04 23:57:38,923 INFO    SenderThread:10952 [sender.py:send_request_defer():581] handle sender defer: 9
2023-02-04 23:57:38,923 INFO    SenderThread:10952 [dir_watcher.py:finish():362] shutting down directory watcher
2023-02-04 23:57:39,601 INFO    SenderThread:10952 [dir_watcher.py:finish():392] scan: /home/lume/KARPATHY/nanoGPT/wandb/run-20230204_235600-ge9paqob/files
2023-02-04 23:57:39,602 INFO    SenderThread:10952 [dir_watcher.py:finish():406] scan save: /home/lume/KARPATHY/nanoGPT/wandb/run-20230204_235600-ge9paqob/files/requirements.txt requirements.txt
2023-02-04 23:57:39,602 INFO    SenderThread:10952 [dir_watcher.py:finish():406] scan save: /home/lume/KARPATHY/nanoGPT/wandb/run-20230204_235600-ge9paqob/files/wandb-metadata.json wandb-metadata.json
2023-02-04 23:57:39,602 INFO    SenderThread:10952 [dir_watcher.py:finish():406] scan save: /home/lume/KARPATHY/nanoGPT/wandb/run-20230204_235600-ge9paqob/files/wandb-summary.json wandb-summary.json
2023-02-04 23:57:39,602 INFO    SenderThread:10952 [dir_watcher.py:finish():406] scan save: /home/lume/KARPATHY/nanoGPT/wandb/run-20230204_235600-ge9paqob/files/output.log output.log
2023-02-04 23:57:39,602 INFO    SenderThread:10952 [dir_watcher.py:finish():406] scan save: /home/lume/KARPATHY/nanoGPT/wandb/run-20230204_235600-ge9paqob/files/config.yaml config.yaml
2023-02-04 23:57:39,602 INFO    SenderThread:10952 [sender.py:transition_state():585] send defer: 10
2023-02-04 23:57:39,602 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: defer
2023-02-04 23:57:39,604 INFO    HandlerThread:10952 [handler.py:handle_request_defer():170] handle defer: 10
2023-02-04 23:57:39,604 DEBUG   SenderThread:10952 [sender.py:send_request():361] send_request: defer
2023-02-04 23:57:39,605 INFO    SenderThread:10952 [sender.py:send_request_defer():581] handle sender defer: 10
2023-02-04 23:57:39,605 INFO    SenderThread:10952 [file_pusher.py:finish():160] shutting down file pusher
2023-02-04 23:57:40,235 INFO    Thread-17 :10952 [upload_job.py:push():143] Uploaded file /home/lume/KARPATHY/nanoGPT/wandb/run-20230204_235600-ge9paqob/files/requirements.txt
2023-02-04 23:57:40,237 INFO    Thread-18 :10952 [upload_job.py:push():143] Uploaded file /home/lume/KARPATHY/nanoGPT/wandb/run-20230204_235600-ge9paqob/files/wandb-summary.json
2023-02-04 23:57:40,240 INFO    Thread-20 :10952 [upload_job.py:push():143] Uploaded file /home/lume/KARPATHY/nanoGPT/wandb/run-20230204_235600-ge9paqob/files/config.yaml
2023-02-04 23:57:40,573 INFO    Thread-19 :10952 [upload_job.py:push():143] Uploaded file /home/lume/KARPATHY/nanoGPT/wandb/run-20230204_235600-ge9paqob/files/output.log
2023-02-04 23:57:40,773 INFO    Thread-12 :10952 [sender.py:transition_state():585] send defer: 11
2023-02-04 23:57:40,773 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: defer
2023-02-04 23:57:40,774 INFO    HandlerThread:10952 [handler.py:handle_request_defer():170] handle defer: 11
2023-02-04 23:57:40,774 DEBUG   SenderThread:10952 [sender.py:send_request():361] send_request: defer
2023-02-04 23:57:40,774 INFO    SenderThread:10952 [sender.py:send_request_defer():581] handle sender defer: 11
2023-02-04 23:57:40,774 INFO    SenderThread:10952 [file_pusher.py:join():165] waiting for file pusher
2023-02-04 23:57:40,774 INFO    SenderThread:10952 [sender.py:transition_state():585] send defer: 12
2023-02-04 23:57:40,774 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: defer
2023-02-04 23:57:40,774 INFO    HandlerThread:10952 [handler.py:handle_request_defer():170] handle defer: 12
2023-02-04 23:57:40,774 DEBUG   SenderThread:10952 [sender.py:send_request():361] send_request: defer
2023-02-04 23:57:40,774 INFO    SenderThread:10952 [sender.py:send_request_defer():581] handle sender defer: 12
2023-02-04 23:57:41,304 INFO    SenderThread:10952 [sender.py:transition_state():585] send defer: 13
2023-02-04 23:57:41,304 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: defer
2023-02-04 23:57:41,304 INFO    HandlerThread:10952 [handler.py:handle_request_defer():170] handle defer: 13
2023-02-04 23:57:41,304 DEBUG   SenderThread:10952 [sender.py:send_request():361] send_request: defer
2023-02-04 23:57:41,304 INFO    SenderThread:10952 [sender.py:send_request_defer():581] handle sender defer: 13
2023-02-04 23:57:41,305 INFO    SenderThread:10952 [sender.py:transition_state():585] send defer: 14
2023-02-04 23:57:41,305 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: defer
2023-02-04 23:57:41,305 INFO    HandlerThread:10952 [handler.py:handle_request_defer():170] handle defer: 14
2023-02-04 23:57:41,305 DEBUG   SenderThread:10952 [sender.py:send():334] send: final
2023-02-04 23:57:41,305 DEBUG   SenderThread:10952 [sender.py:send():334] send: footer
2023-02-04 23:57:41,305 DEBUG   SenderThread:10952 [sender.py:send_request():361] send_request: defer
2023-02-04 23:57:41,305 INFO    SenderThread:10952 [sender.py:send_request_defer():581] handle sender defer: 14
2023-02-04 23:57:41,305 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: poll_exit
2023-02-04 23:57:41,306 DEBUG   SenderThread:10952 [sender.py:send_request():361] send_request: poll_exit
2023-02-04 23:57:41,306 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: server_info
2023-02-04 23:57:41,306 DEBUG   SenderThread:10952 [sender.py:send_request():361] send_request: server_info
2023-02-04 23:57:41,308 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: get_summary
2023-02-04 23:57:41,308 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: sampled_history
2023-02-04 23:57:41,493 INFO    MainThread:10952 [wandb_run.py:_footer_history_summary_info():3427] rendering history
2023-02-04 23:57:41,494 INFO    MainThread:10952 [wandb_run.py:_footer_history_summary_info():3459] rendering summary
2023-02-04 23:57:41,494 INFO    MainThread:10952 [wandb_run.py:_footer_sync_info():3383] logging synced files
2023-02-04 23:57:41,494 DEBUG   HandlerThread:10952 [handler.py:handle_request():144] handle_request: shutdown
2023-02-04 23:57:41,494 INFO    HandlerThread:10952 [handler.py:finish():841] shutting down handler
2023-02-04 23:57:42,306 INFO    WriterThread:10952 [datastore.py:close():299] close: /home/lume/KARPATHY/nanoGPT/wandb/run-20230204_235600-ge9paqob/run-ge9paqob.wandb
2023-02-04 23:57:42,493 INFO    SenderThread:10952 [sender.py:finish():1491] shutting down sender
2023-02-04 23:57:42,494 INFO    SenderThread:10952 [file_pusher.py:finish():160] shutting down file pusher
2023-02-04 23:57:42,494 INFO    SenderThread:10952 [file_pusher.py:join():165] waiting for file pusher
