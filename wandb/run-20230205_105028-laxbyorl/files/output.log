
step 0: train loss 11.0203, val loss 11.0147
iter 0: loss 11.0055, time 19983.42ms
iter 10: loss 9.9733, time 455.82ms
iter 20: loss 9.4787, time 455.37ms
iter 30: loss 9.2344, time 456.82ms
iter 40: loss 9.0865, time 456.80ms
iter 50: loss 8.2044, time 455.80ms
iter 60: loss 8.2956, time 456.70ms
iter 70: loss 7.7345, time 456.10ms
iter 80: loss 7.8050, time 456.68ms
iter 90: loss 7.4728, time 457.52ms
iter 100: loss 6.9683, time 456.45ms
iter 110: loss 7.1629, time 456.12ms
iter 120: loss 7.0023, time 456.87ms
iter 130: loss 7.3028, time 458.36ms
iter 140: loss 7.1423, time 456.53ms
iter 150: loss 7.6471, time 457.04ms
iter 160: loss 7.1155, time 457.66ms
iter 170: loss 6.7254, time 457.07ms
iter 180: loss 6.9254, time 457.31ms
iter 190: loss 7.0134, time 457.59ms
iter 200: loss 6.7040, time 457.64ms
iter 210: loss 7.1996, time 458.71ms
iter 220: loss 6.9042, time 458.41ms
iter 230: loss 6.3197, time 456.82ms
iter 240: loss 6.1512, time 458.25ms
iter 250: loss 6.7921, time 457.44ms
iter 260: loss 6.5696, time 457.66ms
iter 270: loss 5.8326, time 458.60ms
iter 280: loss 6.9559, time 458.58ms
iter 290: loss 6.6252, time 457.22ms
iter 300: loss 6.8734, time 455.86ms
iter 310: loss 6.8190, time 458.32ms
iter 320: loss 6.8162, time 458.02ms
iter 330: loss 5.9286, time 459.60ms
iter 340: loss 6.4032, time 458.66ms
iter 350: loss 6.4575, time 458.28ms
iter 360: loss 6.6016, time 457.22ms
iter 370: loss 6.2064, time 457.42ms
iter 380: loss 6.6813, time 458.22ms
iter 390: loss 6.1161, time 458.42ms
iter 400: loss 6.0625, time 457.37ms
iter 410: loss 6.2498, time 456.47ms
iter 420: loss 5.7784, time 457.73ms
iter 430: loss 6.0455, time 457.49ms
iter 440: loss 6.4195, time 458.94ms
iter 450: loss 6.0884, time 458.54ms
iter 460: loss 6.5279, time 457.49ms
iter 470: loss 6.6510, time 457.52ms
iter 480: loss 6.6809, time 457.65ms
iter 490: loss 5.7900, time 458.15ms
step 500: train loss 6.4402, val loss 6.4098
saving checkpoint to out
iter 500: loss 6.5868, time 12954.55ms
iter 510: loss 6.4364, time 458.28ms
iter 520: loss 6.7138, time 455.75ms
iter 530: loss 5.7646, time 457.93ms
iter 540: loss 7.5199, time 457.04ms
iter 550: loss 6.5551, time 457.72ms
iter 560: loss 5.8508, time 458.17ms
iter 570: loss 6.1745, time 457.64ms
iter 580: loss 7.0893, time 457.19ms
iter 590: loss 7.1086, time 458.69ms
iter 600: loss 6.4439, time 457.93ms
iter 610: loss 6.4394, time 459.24ms
iter 620: loss 6.2286, time 458.53ms
iter 630: loss 6.3602, time 458.64ms
iter 640: loss 5.7352, time 458.09ms
iter 650: loss 6.2288, time 456.49ms
iter 660: loss 6.1271, time 457.79ms
iter 670: loss 6.1635, time 458.30ms
iter 680: loss 6.0879, time 458.60ms
iter 690: loss 5.8184, time 459.52ms
iter 700: loss 5.8719, time 460.41ms
iter 710: loss 6.4804, time 457.57ms
iter 720: loss 6.1118, time 458.30ms
iter 730: loss 5.7644, time 457.98ms
iter 740: loss 6.1975, time 457.82ms
iter 750: loss 6.3594, time 459.19ms
iter 760: loss 6.0899, time 458.72ms
iter 770: loss 6.3829, time 459.76ms
iter 780: loss 6.1684, time 457.73ms
iter 790: loss 6.3854, time 457.95ms
iter 800: loss 6.1282, time 457.72ms
iter 810: loss 6.1705, time 458.12ms
iter 820: loss 6.2596, time 457.84ms
iter 830: loss 6.4576, time 458.64ms
iter 840: loss 6.5319, time 458.82ms
iter 850: loss 6.7096, time 458.73ms
iter 860: loss 5.9273, time 457.61ms
iter 870: loss 5.9294, time 457.78ms
iter 880: loss 6.7575, time 458.55ms
iter 890: loss 5.9228, time 459.80ms
iter 900: loss 5.6507, time 458.36ms
iter 910: loss 6.6749, time 457.51ms
iter 920: loss 6.5146, time 457.87ms
iter 930: loss 6.2278, time 457.99ms
iter 940: loss 6.2620, time 458.47ms
iter 950: loss 6.7172, time 458.27ms
iter 960: loss 5.8366, time 459.10ms
iter 970: loss 6.2421, time 458.52ms
iter 980: loss 5.9463, time 459.54ms
iter 990: loss 6.2936, time 459.16ms
step 1000: train loss 6.1845, val loss 6.1791
saving checkpoint to out
iter 1000: loss 6.5870, time 12924.22ms
iter 1010: loss 5.8403, time 457.83ms
iter 1020: loss 5.6975, time 458.60ms
iter 1030: loss 5.9424, time 457.75ms
iter 1040: loss 6.9572, time 457.56ms
iter 1050: loss 6.2860, time 457.91ms
iter 1060: loss 6.1933, time 458.24ms
iter 1070: loss 5.9680, time 458.37ms
iter 1080: loss 6.2784, time 458.07ms
iter 1090: loss 6.1276, time 457.68ms
iter 1100: loss 5.5101, time 457.98ms
iter 1110: loss 6.6050, time 458.07ms
iter 1120: loss 5.9792, time 458.37ms
iter 1130: loss 5.9439, time 457.44ms
iter 1140: loss 6.2581, time 457.05ms
iter 1150: loss 5.6870, time 457.41ms
iter 1160: loss 6.1413, time 458.27ms
iter 1170: loss 6.2752, time 458.48ms
iter 1180: loss 6.1107, time 459.04ms
iter 1190: loss 5.3518, time 458.86ms
iter 1200: loss 6.2203, time 459.02ms
iter 1210: loss 5.4524, time 457.59ms
iter 1220: loss 6.2100, time 458.62ms
iter 1230: loss 6.2165, time 459.04ms
iter 1240: loss 6.6896, time 458.79ms
iter 1250: loss 5.6108, time 458.06ms
iter 1260: loss 6.1427, time 458.86ms
iter 1270: loss 5.7608, time 459.00ms
iter 1280: loss 5.9174, time 457.08ms
iter 1290: loss 5.8652, time 457.09ms
iter 1300: loss 5.7615, time 458.33ms
iter 1310: loss 5.8156, time 457.67ms
iter 1320: loss 5.7891, time 458.90ms
iter 1330: loss 6.6250, time 459.98ms
iter 1340: loss 6.3727, time 459.64ms
iter 1350: loss 6.1691, time 457.17ms
iter 1360: loss 5.7952, time 457.70ms
iter 1370: loss 5.8704, time 457.92ms
iter 1380: loss 5.5997, time 458.41ms
iter 1390: loss 6.2913, time 459.20ms
iter 1400: loss 5.0358, time 458.91ms
iter 1410: loss 6.5105, time 457.61ms
iter 1420: loss 6.3922, time 457.36ms
iter 1430: loss 5.2949, time 458.20ms
iter 1440: loss 6.0230, time 457.59ms
iter 1450: loss 6.0009, time 457.30ms
iter 1460: loss 6.2850, time 457.33ms
iter 1470: loss 6.1571, time 457.42ms
iter 1480: loss 5.8797, time 457.42ms
iter 1490: loss 5.2408, time 457.77ms
step 1500: train loss 5.9930, val loss 6.0131
saving checkpoint to out
iter 1500: loss 5.8470, time 73170.24ms
iter 1510: loss 5.7712, time 450.94ms
iter 1520: loss 5.9527, time 451.30ms
iter 1530: loss 5.7465, time 455.75ms
iter 1540: loss 5.8632, time 454.02ms
iter 1550: loss 6.4178, time 454.41ms
iter 1560: loss 6.1418, time 454.93ms
iter 1570: loss 6.0347, time 456.42ms
iter 1580: loss 6.6680, time 454.33ms
iter 1590: loss 6.0615, time 455.10ms
iter 1600: loss 5.2326, time 455.88ms
iter 1610: loss 6.2019, time 455.79ms
iter 1620: loss 5.5780, time 454.95ms
iter 1630: loss 5.6477, time 456.34ms
iter 1640: loss 5.7491, time 456.65ms
iter 1650: loss 5.8934, time 454.87ms
iter 1660: loss 5.7000, time 457.16ms
iter 1670: loss 6.2186, time 457.17ms
iter 1680: loss 5.5335, time 455.69ms
iter 1690: loss 5.9303, time 457.12ms
iter 1700: loss 5.5464, time 456.96ms
iter 1710: loss 5.4259, time 455.83ms
iter 1720: loss 5.2138, time 456.11ms
iter 1730: loss 5.5487, time 456.73ms
iter 1740: loss 6.3028, time 456.13ms
iter 1750: loss 5.6648, time 457.57ms
iter 1760: loss 6.1332, time 457.47ms
iter 1770: loss 6.2614, time 456.35ms
iter 1780: loss 5.3821, time 455.75ms
iter 1790: loss 5.7586, time 455.89ms
iter 1800: loss 5.0830, time 458.54ms
iter 1810: loss 6.4333, time 456.53ms
iter 1820: loss 6.7422, time 457.37ms
iter 1830: loss 6.3546, time 457.40ms
iter 1840: loss 5.5632, time 458.24ms
iter 1850: loss 5.7234, time 457.48ms
iter 1860: loss 6.6657, time 457.42ms
iter 1870: loss 6.2170, time 456.74ms
iter 1880: loss 6.0039, time 458.17ms
iter 1890: loss 5.5158, time 457.13ms
iter 1900: loss 5.8113, time 456.59ms
iter 1910: loss 6.3505, time 457.01ms
iter 1920: loss 6.7874, time 457.67ms
iter 1930: loss 5.6988, time 456.72ms
iter 1940: loss 6.2386, time 456.58ms
iter 1950: loss 5.9775, time 457.56ms
iter 1960: loss 6.0753, time 457.47ms
iter 1970: loss 5.2848, time 456.92ms
iter 1980: loss 5.6741, time 456.91ms
iter 1990: loss 6.1153, time 457.26ms
step 2000: train loss 5.8501, val loss 5.8186
saving checkpoint to out
iter 2000: loss 5.4550, time 13033.25ms
iter 2010: loss 5.6052, time 456.45ms
iter 2020: loss 5.6381, time 457.78ms
iter 2030: loss 6.9011, time 455.98ms
iter 2040: loss 5.5629, time 457.28ms
iter 2050: loss 5.6626, time 456.93ms
iter 2060: loss 5.3278, time 457.23ms
iter 2070: loss 6.1515, time 456.63ms
iter 2080: loss 6.1018, time 456.68ms
iter 2090: loss 6.1574, time 457.08ms
iter 2100: loss 5.4251, time 457.30ms
iter 2110: loss 5.7294, time 456.22ms
iter 2120: loss 5.6436, time 457.42ms
iter 2130: loss 6.3213, time 456.65ms
iter 2140: loss 5.9190, time 457.50ms
iter 2150: loss 5.5942, time 455.83ms
iter 2160: loss 5.2188, time 456.68ms
iter 2170: loss 6.2432, time 457.15ms
iter 2180: loss 5.4795, time 456.13ms
iter 2190: loss 6.7113, time 457.00ms
iter 2200: loss 5.3434, time 457.38ms
iter 2210: loss 6.2273, time 457.29ms
iter 2220: loss 5.8209, time 456.93ms
iter 2230: loss 5.6018, time 456.84ms
iter 2240: loss 5.6171, time 457.35ms
iter 2250: loss 5.8663, time 457.28ms
iter 2260: loss 5.6944, time 457.30ms
iter 2270: loss 5.0916, time 456.83ms
iter 2280: loss 5.1051, time 456.87ms
iter 2290: loss 5.8443, time 457.88ms
iter 2300: loss 5.3635, time 456.90ms
iter 2310: loss 6.1107, time 456.82ms
iter 2320: loss 5.5666, time 457.30ms
iter 2330: loss 5.7667, time 457.86ms
iter 2340: loss 6.0503, time 455.33ms
iter 2350: loss 5.4194, time 456.77ms
iter 2360: loss 5.6302, time 456.18ms
iter 2370: loss 5.1379, time 455.99ms
iter 2380: loss 6.3728, time 456.44ms
iter 2390: loss 5.4846, time 457.10ms
iter 2400: loss 5.2080, time 456.43ms
iter 2410: loss 5.9632, time 456.99ms
iter 2420: loss 6.0161, time 458.39ms
iter 2430: loss 5.1659, time 458.47ms
iter 2440: loss 5.6691, time 457.98ms
iter 2450: loss 6.2885, time 456.57ms
iter 2460: loss 5.9736, time 457.71ms
iter 2470: loss 5.5535, time 457.03ms
iter 2480: loss 6.0791, time 457.67ms
iter 2490: loss 6.0780, time 457.39ms
step 2500: train loss 5.6684, val loss 5.6500
saving checkpoint to out
iter 2500: loss 5.4646, time 12985.74ms
iter 2510: loss 5.9438, time 456.38ms
iter 2520: loss 5.5914, time 457.62ms
iter 2530: loss 4.8539, time 456.93ms
iter 2540: loss 5.3319, time 456.39ms
iter 2550: loss 5.3990, time 456.12ms
iter 2560: loss 5.5943, time 457.81ms
iter 2570: loss 5.2798, time 457.77ms
iter 2580: loss 5.1222, time 456.05ms
iter 2590: loss 5.9520, time 457.82ms
iter 2600: loss 5.1365, time 458.06ms
iter 2610: loss 5.4058, time 457.94ms
iter 2620: loss 5.4883, time 455.87ms
iter 2630: loss 4.9144, time 457.12ms
iter 2640: loss 5.6490, time 459.75ms
iter 2650: loss 5.6090, time 458.35ms
iter 2660: loss 5.3211, time 456.78ms
iter 2670: loss 5.8504, time 457.26ms
iter 2680: loss 5.7427, time 458.21ms
iter 2690: loss 5.6313, time 458.35ms
iter 2700: loss 5.7166, time 458.96ms
iter 2710: loss 4.9150, time 458.15ms
iter 2720: loss 5.5687, time 457.92ms
iter 2730: loss 6.0016, time 457.82ms
iter 2740: loss 5.8217, time 457.75ms
iter 2750: loss 5.1643, time 458.68ms
iter 2760: loss 5.0593, time 458.35ms
iter 2770: loss 5.6490, time 459.20ms
iter 2780: loss 5.6632, time 457.90ms
iter 2790: loss 5.3083, time 457.32ms
iter 2800: loss 5.1497, time 458.17ms
iter 2810: loss 5.3505, time 458.66ms
iter 2820: loss 5.6190, time 458.86ms
iter 2830: loss 6.1369, time 459.69ms
iter 2840: loss 5.2375, time 459.53ms
iter 2850: loss 5.1258, time 458.58ms
iter 2860: loss 5.7809, time 457.83ms
iter 2870: loss 5.0837, time 458.50ms
iter 2880: loss 5.2128, time 458.10ms
iter 2890: loss 4.6821, time 458.62ms
iter 2900: loss 5.5250, time 458.33ms
iter 2910: loss 5.6199, time 456.71ms
iter 2920: loss 6.2040, time 457.87ms
iter 2930: loss 5.6652, time 457.37ms
iter 2940: loss 5.9621, time 458.13ms
iter 2950: loss 5.4978, time 458.69ms
iter 2960: loss 5.4430, time 457.99ms
iter 2970: loss 5.7511, time 459.78ms
iter 2980: loss 5.2084, time 459.14ms
iter 2990: loss 5.3316, time 458.39ms
step 3000: train loss 5.5289, val loss 5.4596
saving checkpoint to out
iter 3000: loss 5.0843, time 12912.30ms
iter 3010: loss 4.9768, time 457.54ms
iter 3020: loss 6.8499, time 458.20ms
iter 3030: loss 5.7236, time 457.79ms
iter 3040: loss 5.5150, time 456.49ms
iter 3050: loss 5.2848, time 457.98ms
iter 3060: loss 5.2282, time 457.12ms
iter 3070: loss 5.7494, time 457.58ms
iter 3080: loss 5.5728, time 457.30ms
iter 3090: loss 5.4592, time 457.25ms
iter 3100: loss 5.6867, time 457.53ms
iter 3110: loss 5.2764, time 456.88ms
iter 3120: loss 6.3074, time 457.79ms
iter 3130: loss 4.6742, time 457.09ms
iter 3140: loss 5.8931, time 458.17ms
iter 3150: loss 4.7324, time 457.93ms
iter 3160: loss 5.7534, time 458.52ms
iter 3170: loss 5.5507, time 457.44ms
iter 3180: loss 5.8545, time 458.29ms
iter 3190: loss 5.2593, time 458.09ms
iter 3200: loss 5.0839, time 457.46ms
iter 3210: loss 4.8560, time 457.41ms
iter 3220: loss 5.6451, time 456.01ms
iter 3230: loss 5.2316, time 458.28ms
iter 3240: loss 5.8279, time 458.59ms
iter 3250: loss 5.3146, time 458.58ms
iter 3260: loss 5.5161, time 457.40ms
iter 3270: loss 5.5228, time 457.66ms
iter 3280: loss 5.4127, time 458.25ms
iter 3290: loss 5.1819, time 457.98ms
iter 3300: loss 5.8075, time 457.17ms
iter 3310: loss 5.4301, time 457.15ms
iter 3320: loss 5.4662, time 457.61ms
iter 3330: loss 5.8101, time 458.90ms
iter 3340: loss 5.6897, time 459.58ms
iter 3350: loss 5.7405, time 458.67ms
iter 3360: loss 5.6868, time 456.99ms
iter 3370: loss 5.6228, time 457.81ms
iter 3380: loss 5.6155, time 458.26ms
iter 3390: loss 5.8465, time 458.33ms
iter 3400: loss 5.1196, time 459.04ms
iter 3410: loss 5.0009, time 456.42ms
iter 3420: loss 5.2385, time 457.79ms
iter 3430: loss 5.3680, time 457.88ms
iter 3440: loss 5.2638, time 458.53ms
iter 3450: loss 5.3159, time 457.55ms
iter 3460: loss 5.0614, time 457.30ms
iter 3470: loss 5.2565, time 458.35ms
iter 3480: loss 5.5672, time 457.67ms
iter 3490: loss 4.8633, time 457.31ms
step 3500: train loss 5.3893, val loss 5.3703
saving checkpoint to out
iter 3500: loss 5.0115, time 31310.24ms
iter 3510: loss 5.4455, time 467.18ms
iter 3520: loss 5.7615, time 455.82ms
iter 3530: loss 4.9695, time 454.64ms
iter 3540: loss 6.1538, time 456.14ms
iter 3550: loss 5.3980, time 455.97ms
iter 3560: loss 5.1190, time 456.50ms
iter 3570: loss 4.8870, time 456.53ms
iter 3580: loss 5.4953, time 455.87ms
iter 3590: loss 5.2893, time 457.74ms
iter 3600: loss 5.2853, time 457.17ms
iter 3610: loss 4.4898, time 457.27ms
iter 3620: loss 4.9423, time 455.97ms
iter 3630: loss 5.2365, time 456.28ms
iter 3640: loss 5.1225, time 458.61ms
iter 3650: loss 4.8335, time 472.41ms
iter 3660: loss 5.0229, time 721.74ms
iter 3670: loss 5.4602, time 456.27ms
iter 3680: loss 5.3423, time 458.01ms
iter 3690: loss 5.2238, time 457.63ms
iter 3700: loss 6.1699, time 456.50ms
iter 3710: loss 5.2148, time 456.87ms
iter 3720: loss 5.2141, time 457.10ms
iter 3730: loss 5.3563, time 456.75ms
iter 3740: loss 5.5570, time 457.80ms
iter 3750: loss 5.2622, time 457.18ms
iter 3760: loss 5.4960, time 457.28ms
iter 3770: loss 5.6686, time 456.23ms
iter 3780: loss 4.8101, time 457.85ms
iter 3790: loss 5.7137, time 457.47ms
iter 3800: loss 5.2394, time 456.60ms
iter 3810: loss 5.2120, time 457.05ms
iter 3820: loss 6.0490, time 457.43ms
iter 3830: loss 5.1119, time 459.41ms
iter 3840: loss 5.1473, time 455.95ms
iter 3850: loss 5.4187, time 457.19ms
iter 3860: loss 5.0381, time 457.30ms
iter 3870: loss 5.3818, time 458.47ms
iter 3880: loss 4.6300, time 458.45ms
iter 3890: loss 5.6055, time 457.86ms
iter 3900: loss 5.4455, time 456.77ms
iter 3910: loss 5.3325, time 457.91ms
iter 3920: loss 5.0883, time 457.10ms
iter 3930: loss 4.9424, time 457.21ms
iter 3940: loss 5.2025, time 456.45ms
iter 3950: loss 5.5685, time 501.41ms
iter 3960: loss 5.2421, time 457.73ms
iter 3970: loss 5.2947, time 458.78ms
iter 3980: loss 5.8344, time 457.93ms
iter 3990: loss 5.4315, time 457.17ms
step 4000: train loss 5.3068, val loss 5.3100
saving checkpoint to out
iter 4000: loss 5.9428, time 31166.03ms
iter 4010: loss 5.1245, time 452.72ms
iter 4020: loss 5.6237, time 455.10ms
iter 4030: loss 5.0031, time 455.91ms
iter 4040: loss 5.0712, time 456.09ms
iter 4050: loss 5.0787, time 456.45ms
iter 4060: loss 5.1810, time 457.53ms
iter 4070: loss 5.7920, time 456.24ms
iter 4080: loss 5.9136, time 455.65ms
iter 4090: loss 5.8187, time 458.05ms
iter 4100: loss 5.5233, time 457.24ms
iter 4110: loss 5.2620, time 456.66ms
iter 4120: loss 5.3896, time 457.71ms
iter 4130: loss 6.2232, time 458.15ms
iter 4140: loss 4.8446, time 458.15ms
iter 4150: loss 5.6141, time 456.76ms
iter 4160: loss 5.2512, time 456.87ms
iter 4170: loss 4.7473, time 458.50ms
iter 4180: loss 6.3821, time 458.06ms
iter 4190: loss 5.0669, time 458.63ms
iter 4200: loss 5.4749, time 457.54ms
iter 4210: loss 4.3275, time 456.96ms
iter 4220: loss 5.1956, time 457.99ms
iter 4230: loss 4.8057, time 458.63ms
iter 4240: loss 5.0991, time 458.52ms
iter 4250: loss 5.0030, time 458.23ms
iter 4260: loss 5.6126, time 457.79ms
iter 4270: loss 5.1976, time 458.17ms
iter 4280: loss 5.5947, time 457.91ms
iter 4290: loss 5.1063, time 458.27ms
iter 4300: loss 5.2218, time 458.93ms
iter 4310: loss 5.4244, time 458.91ms
iter 4320: loss 4.9402, time 457.82ms
iter 4330: loss 5.4329, time 457.98ms
iter 4340: loss 5.1401, time 457.08ms
iter 4350: loss 4.9176, time 458.39ms
iter 4360: loss 5.5771, time 459.21ms
iter 4370: loss 4.9266, time 459.37ms
iter 4380: loss 5.2451, time 457.95ms
iter 4390: loss 5.0166, time 458.26ms
iter 4400: loss 5.1967, time 457.88ms
iter 4410: loss 5.5136, time 458.54ms
iter 4420: loss 4.8690, time 457.69ms
iter 4430: loss 5.4388, time 458.92ms
iter 4440: loss 5.1434, time 458.80ms
iter 4450: loss 5.8424, time 457.12ms
iter 4460: loss 5.2774, time 457.68ms
iter 4470: loss 5.3780, time 457.61ms
iter 4480: loss 4.6598, time 458.12ms
iter 4490: loss 5.2479, time 458.35ms
step 4500: train loss 5.1873, val loss 5.2368
saving checkpoint to out
iter 4500: loss 4.9427, time 13180.27ms
iter 4510: loss 5.1882, time 458.19ms
iter 4520: loss 5.5440, time 457.12ms
iter 4530: loss 5.3184, time 456.93ms
iter 4540: loss 5.2325, time 457.46ms
iter 4550: loss 4.8567, time 458.06ms
iter 4560: loss 5.1008, time 457.11ms
iter 4570: loss 4.7949, time 457.23ms
iter 4580: loss 4.6449, time 457.92ms
iter 4590: loss 5.6176, time 458.47ms
iter 4600: loss 5.0587, time 459.17ms
iter 4610: loss 5.2620, time 458.60ms
iter 4620: loss 5.0872, time 458.44ms
iter 4630: loss 4.8917, time 457.23ms
iter 4640: loss 5.0931, time 457.90ms
iter 4650: loss 5.0903, time 457.20ms
iter 4660: loss 5.2841, time 458.94ms
iter 4670: loss 5.5022, time 458.01ms
iter 4680: loss 5.0913, time 457.99ms
iter 4690: loss 4.9778, time 456.44ms
iter 4700: loss 5.0506, time 457.11ms
iter 4710: loss 5.2640, time 459.48ms
iter 4720: loss 5.1167, time 458.31ms
iter 4730: loss 5.5335, time 457.94ms
iter 4740: loss 5.6887, time 459.21ms
iter 4750: loss 5.0983, time 458.25ms
iter 4760: loss 4.9837, time 458.65ms
iter 4770: loss 4.9822, time 457.34ms
iter 4780: loss 5.7511, time 458.50ms
iter 4790: loss 5.4027, time 459.41ms
iter 4800: loss 5.0305, time 458.70ms
iter 4810: loss 4.7179, time 458.48ms
iter 4820: loss 5.5462, time 458.16ms
iter 4830: loss 5.1413, time 458.65ms
iter 4840: loss 5.2178, time 457.18ms
iter 4850: loss 4.9841, time 458.10ms
iter 4860: loss 5.0244, time 458.92ms
iter 4870: loss 4.7023, time 458.28ms
iter 4880: loss 5.7253, time 457.82ms
iter 4890: loss 5.5147, time 457.92ms
iter 4900: loss 5.2862, time 458.42ms
iter 4910: loss 5.1644, time 457.17ms
iter 4920: loss 5.7848, time 458.61ms
iter 4930: loss 4.9069, time 458.74ms
iter 4940: loss 4.9386, time 458.56ms
iter 4950: loss 4.9771, time 457.26ms
iter 4960: loss 5.2857, time 457.50ms
iter 4970: loss 5.1685, time 458.10ms
iter 4980: loss 5.1748, time 458.21ms
iter 4990: loss 4.6796, time 459.04ms
step 5000: train loss 5.1758, val loss 5.2326
saving checkpoint to out
iter 5000: loss 5.9186, time 265617.34ms
iter 5010: loss 5.3554, time 449.36ms
iter 5020: loss 5.0754, time 450.48ms
iter 5030: loss 5.8793, time 450.48ms
iter 5040: loss 5.1699, time 450.66ms
iter 5050: loss 4.8193, time 451.22ms
iter 5060: loss 5.1592, time 452.83ms
iter 5070: loss 5.8370, time 452.54ms
iter 5080: loss 4.9880, time 453.47ms
iter 5090: loss 4.9852, time 454.31ms
iter 5100: loss 5.3166, time 454.30ms
iter 5110: loss 5.0421, time 453.35ms
iter 5120: loss 5.1270, time 453.11ms
iter 5130: loss 5.0615, time 455.81ms
iter 5140: loss 4.8589, time 454.36ms
iter 5150: loss 5.5615, time 456.87ms
Traceback (most recent call last):
  File "train.py", line 289, in <module>
    torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)
  File "/home/lume/.local/lib/python3.8/site-packages/torch/nn/utils/clip_grad.py", line 77, in clip_grad_norm_
    torch._foreach_mul_(grads, clip_coef_clamped.to(device))  # type: ignore[call-overload]
KeyboardInterrupt
Traceback (most recent call last):
  File "train.py", line 289, in <module>
    torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)
  File "/home/lume/.local/lib/python3.8/site-packages/torch/nn/utils/clip_grad.py", line 77, in clip_grad_norm_
    torch._foreach_mul_(grads, clip_coef_clamped.to(device))  # type: ignore[call-overload]
KeyboardInterrupt